{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dMUvZrch2Yg",
        "outputId": "e6d27e8c-1bd0-426c-9da7-95e32d0463ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/datasnaek/youtube-new?dataset_version_number=115...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 201M/201M [00:05<00:00, 37.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/datasnaek/youtube-new/versions/115\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Trending Youtube Video Dataset From Kaggle\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"datasnaek/youtube-new\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj7P2Wx1h_vb",
        "outputId": "258113a1-2d67-45df-829c-86a1533c4803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in dataset: ['GB_category_id.json', 'FRvideos.csv', 'GBvideos.csv', 'US_category_id.json', 'JP_category_id.json', 'DE_category_id.json', 'RUvideos.csv', 'JPvideos.csv', 'RU_category_id.json', 'USvideos.csv', 'DEvideos.csv', 'MX_category_id.json', 'INvideos.csv', 'MXvideos.csv', 'FR_category_id.json', 'IN_category_id.json', 'CA_category_id.json', 'KRvideos.csv', 'KR_category_id.json', 'CAvideos.csv']\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(path)\n",
        "print(\"Files in dataset:\", files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P_dO22IbiuSk",
        "outputId": "4d1208bd-6be2-44d4-bc87-2cb770e0bab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      video_id trending_date  \\\n",
            "0  2kyS6SvSYSE      17.14.11   \n",
            "1  1ZAPwfrtAFY      17.14.11   \n",
            "2  5qpjK5DgCt4      17.14.11   \n",
            "3  puqaWrEC7tY      17.14.11   \n",
            "4  d380meD0W0M      17.14.11   \n",
            "\n",
            "                                               title          channel_title  \\\n",
            "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
            "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
            "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
            "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
            "4                           I Dare You: GOING BALD!?               nigahiga   \n",
            "\n",
            "   category_id              publish_time  \\\n",
            "0           22  2017-11-13T17:13:01.000Z   \n",
            "1           24  2017-11-13T07:30:00.000Z   \n",
            "2           23  2017-11-12T19:05:24.000Z   \n",
            "3           24  2017-11-13T11:00:04.000Z   \n",
            "4           24  2017-11-12T18:01:41.000Z   \n",
            "\n",
            "                                                tags    views   likes  \\\n",
            "0                                    SHANtell martin   748374   57527   \n",
            "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
            "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
            "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
            "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
            "\n",
            "   dislikes  comment_count                                  thumbnail_link  \\\n",
            "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
            "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
            "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
            "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
            "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
            "\n",
            "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
            "0              False             False                   False   \n",
            "1              False             False                   False   \n",
            "2              False             False                   False   \n",
            "3              False             False                   False   \n",
            "4              False             False                   False   \n",
            "\n",
            "                                         description  \n",
            "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
            "1  One year after the presidential election, John...  \n",
            "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
            "3  Today we find out if Link is a Nickelback amat...  \n",
            "4  I know it's been a while since we did this sho...  \n"
          ]
        }
      ],
      "source": [
        "file_to_load = os.path.join(path, 'USvideos.csv')\n",
        "if 'USvideos.csv' in files:\n",
        "    data = pd.read_csv(file_to_load)\n",
        "    print(data.head())\n",
        "else:\n",
        "    print(\"The expected file 'USvideos.csv' is not in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IM14GSnGtua",
        "outputId": "8169a187-8fcb-42e8-c411-8198ab30ba96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
            "1  The Trump Presidency: Last Week Tonight with J...   \n",
            "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
            "3                   Nickelback Lyrics: Real or Fake?   \n",
            "4                           I Dare You: GOING BALD!?   \n",
            "\n",
            "                                  title_preprocessed  \n",
            "0                             [want, talk, marriage]  \n",
            "1  [trump, presidency, last, week, tonight, john,...  \n",
            "2  [racist, superman, rudy, mancuso, king, bach, ...  \n",
            "3                   [nickelback, lyrics, real, fake]  \n",
            "4                                [dare, going, bald]  \n"
          ]
        }
      ],
      "source": [
        "# Preprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "#download stopwords - Jessica\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "#load the CSV file\n",
        "\"\"\"\n",
        "file_path = '/content/USvideos.csv'    #we realized with using the kagglehub import that we do not\n",
        "data = pd.read_csv(file_path)          #need to import our dataset, but instead, use kagglehub to download the dataset - Sloane, Jessica, Persabella\n",
        "\"\"\"\n",
        "\n",
        "#Preprocessing function, removes punctuations and stopwords from our video titles - Sloane\n",
        "def preprocess_text_simple(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "#set preprocessing to the 'title' column of our csv file & remove duplications - Jessica\n",
        "data['title_preprocessed'] = data['title'].apply(preprocess_text_simple)\n",
        "data = data.drop_duplicates(subset='title', keep='first')\n",
        "\n",
        "print(data[['title', 'title_preprocessed']].head())   #preview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were having issues with neural networks, specifically with the similarity results being perfect 1s or 99.9% (so, essentially 1). We were using cosine similarity to compute similarity scores, so we tried other methods (besides neural networks and cosine similarities) to see what we could get."
      ],
      "metadata": {
        "id": "vrW2xX7qGdaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the above code, I made a system using a neural network model by dot-product instead of cosine similartiy. Unfortunately, I did not get accurate similarity scores and the code would just recommend the same videos\n",
        "\n",
        "-- Jessica"
      ],
      "metadata": {
        "id": "ksDC5IIkGzg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Recommendations by Euclidean Distance - Sloane\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import time\n",
        "import random\n",
        "\n",
        "start_time = time.time() #starts a timer so we can see how long it takes for the code to run\n",
        "\n",
        "exclude_titles = [\"Where are we?\", \"ME YOU YOU ME\"]         #these two titles always appeared in the results no\n",
        "data = data[~data['title'].isin(exclude_titles)]            #matter what, so i just removed them entirely - Sloane\n",
        "\n",
        "data['title_preprocessed'] = data['title'].apply(preprocess_text_simple) #load the preprocess\n",
        "data = data.drop_duplicates(subset='title', keep='first')\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')  #vectorize the titles\n",
        "title_vectors = vectorizer.fit_transform(data['title_preprocessed'].apply(lambda x: ' '.join(x))).toarray()\n",
        "\n",
        "distances = pairwise_distances(title_vectors, metric='euclidean')\n",
        "\n",
        "similarities = 1 / (1 + distances)  #this converts distance to similarities\n",
        "\n",
        "#recommendation function\n",
        "def recommend_videos_by_title_euclidean(video_index, num_recommendations=10):\n",
        "    sim_scores = list(enumerate(distances[video_index]))\n",
        "    #sort from shortest distance to largest distance\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1])\n",
        "    sim_scores = sim_scores[1:num_recommendations + 1]\n",
        "    video_indices = [i[0] for i in sim_scores]\n",
        "    recommendations = data.iloc[video_indices][['title', 'views']].copy()\n",
        "    recommendations['distance'] = [sim_scores[i][1] for i in range(len(sim_scores))]\n",
        "    recommendations['similarity'] = 1 / (1 + recommendations['distance'])\n",
        "    return recommendations[['title', 'views', 'distance', 'similarity']]\n",
        "\n",
        "\n",
        "random_video_index = random.randint(0, len(data) - 1) #picks a random video\n",
        "print(\"Euclidean Recommendations for:\", data.iloc[random_video_index]['title'])\n",
        "\n",
        "\n",
        "num_recommendations = 10\n",
        "recommendations = recommend_videos_by_title_euclidean(random_video_index, num_recommendations)\n",
        "end_time = time.time() #stops timer after the code completes recommendations\n",
        "print(recommendations)\n",
        "print()\n",
        "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "kjSZliWyHSwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41fc126-6b47-4773-dcec-432f88e86d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Recommendations for: When the girl you're wrestling has a tough little brother  - 979280\n",
            "                                                   title    views  distance  \\\n",
            "38355                  You're Not Edgy, You're Just Lazy   795307  1.199852   \n",
            "16400                               Sumo Wrestling in 4K   655388  1.237355   \n",
            "5678                       I Have (a little bit) HAD IT!   216921  1.263428   \n",
            "10282   Dogs See Their Brother After 10 Months  - 980323     7251  1.268107   \n",
            "30367                 You're Too Good To Date My Friends   705768  1.270018   \n",
            "17     How does your body know you're full? - Hilary ...    78044  1.299193   \n",
            "170       Train - Have Yourself a Merry Little Christmas    30021  1.302036   \n",
            "33539  You're Too Good To Date My Friends | Hardly Wo...  1161472  1.304480   \n",
            "18006               The Girl Next Door (Valentine's Day)    55778  1.304619   \n",
            "26971                    How Girl Scout Cookies Are Made   237087  1.304939   \n",
            "\n",
            "       similarity  \n",
            "38355    0.454576  \n",
            "16400    0.446956  \n",
            "5678     0.441808  \n",
            "10282    0.440896  \n",
            "30367    0.440525  \n",
            "17       0.434935  \n",
            "170      0.434398  \n",
            "33539    0.433937  \n",
            "18006    0.433911  \n",
            "26971    0.433851  \n",
            "\n",
            "Time taken: 21.00 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code was part of a larger project done for an Artificial Intelligence course at Belmont University. I am only uploading my euclidean distance code as well as the necessary preprocessing code."
      ],
      "metadata": {
        "id": "eyJ5gBLNoVS1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}